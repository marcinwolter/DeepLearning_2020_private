{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwiczenia_2a_regresja.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAp3UWPFWDsdvIGBXoV0RR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/DeepLearning_2020_private/blob/main/cwiczenia_2a_regresja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQH7zbVF8v6g"
      },
      "source": [
        "\n",
        "\n",
        "# **Predicting house prices: a regression example**\n",
        "\n",
        "Common type of machine learning problem is \"regression\", which consists of predicting a continuous value instead of a discrete label. For instance, predicting the temperature tomorrow, given meteorological data, or predicting the time that a software project will take to complete, given its specifications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zl5s4feH_v4"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvsAzyjTI3Ie"
      },
      "source": [
        "**1-dimensional data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fEyq6reI8Vi",
        "outputId": "726ac76f-d2bf-4847-bb2f-8e69128373f9"
      },
      "source": [
        "def funct(x):\n",
        "  return x*x*np.sin(x)+np.log(2*x)\n",
        "\n",
        "size = 100\n",
        "low=0\n",
        "high=12\n",
        "error=10\n",
        "\n",
        "XX_train = np.random.uniform(low=low, high=high, size=size)\n",
        "XX_test = np.random.uniform(low=low, high=high, size=size)\n",
        "yy_train = funct(XX_train) + np.random.normal(0., error, size)\n",
        "yy_test = funct(XX_test) + np.random.normal(0., error, size)\n",
        "\n",
        "print(XX_train.shape, yy_train.shape)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,) (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK9f3EkaNLKy"
      },
      "source": [
        "Plot the function and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Jc4wlpu6NPib",
        "outputId": "d640f8cc-36af-45c6-cc03-c6e54cce15e0"
      },
      "source": [
        "fig = plt.figure(figsize=(7,7))\n",
        "\n",
        "plt.plot(XX_train,yy_train, 'o', color='blue', label='Training points')\n",
        "plt.plot(XX_test,yy_test, 'o', color='green', label='Testing points')\n",
        "\n",
        "points = np.linspace(low, high,num=100)\n",
        "plt.plot(points, funct(points),  color='red', label='Function')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7hU2fiZHzl"
      },
      "source": [
        "\n",
        "**Preparing the data**\n",
        "\n",
        "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a unit standard deviation. This is easily done in Numpy:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNzLzYMFZNab"
      },
      "source": [
        "mean = XX_train.mean(axis=0)\n",
        "XX_train_n = XX_train-mean\n",
        "std = XX_train_n.std(axis=0)\n",
        "XX_train_n /= std\n",
        "\n",
        "XX_test_n = XX_test - mean\n",
        "XX_test_n /= std\n",
        "\n",
        "meany = yy_train.mean(axis=0)\n",
        "yy_train_n = yy_train - meany\n",
        "stdy = yy_train_n.std(axis=0)\n",
        "yy_train_n /= stdy\n",
        "\n",
        "yy_test_n = yy_test - meany\n",
        "yy_test_n /= stdy\n",
        "\n",
        "\n",
        "\n",
        "#XX_train_n = XX_train_n.reshape((len(XX_train_n),1))\n",
        "#XX_test_n  = XX_test_n.reshape((len(XX_test_n),1))\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1akSHhNWUOI"
      },
      "source": [
        "Define neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKnzCxTvWlLF",
        "outputId": "6f86f01a-1d76-460e-9bd6-44d949cc8d75"
      },
      "source": [
        "model0 = Sequential(name='network')\n",
        "model0.add(Dense(64, input_shape = (1,), activation = 'relu'))\n",
        "model0.add(Dropout(0.02))\n",
        "model0.add(Dense(64, input_shape = (1,), activation = 'relu'))\n",
        "model0.add(Dropout(0.02))\n",
        "model0.add(Dense(1,activation='linear'))\n",
        "\n",
        "model0.summary()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_102 (Dense)            (None, 64)                128       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,353\n",
            "Trainable params: 4,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9pQ61rwWX9F"
      },
      "source": [
        "Train neural network\n",
        "\n",
        "For regression problems, mean squared error (MSE) is often employed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hos2Vg10XBU3",
        "outputId": "20a5b289-26b1-4cf6-ed6e-5b5ab7ca61ac"
      },
      "source": [
        "#sgd0 = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
        "\n",
        "\n",
        "model0.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
        "history = model0.fit(XX_train_n, yy_train_n, batch_size = 128, epochs = 2000, validation_data=(XX_test_n, yy_test_n), verbose = 1 )"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.1441 - mse: 1.1441 - val_loss: 1.1260 - val_mse: 1.1260\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1326 - mse: 1.1326 - val_loss: 1.0781 - val_mse: 1.0781\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1004 - mse: 1.1004 - val_loss: 1.0341 - val_mse: 1.0341\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0641 - mse: 1.0641 - val_loss: 0.9934 - val_mse: 0.9934\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0308 - mse: 1.0308 - val_loss: 0.9567 - val_mse: 0.9567\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0044 - mse: 1.0044 - val_loss: 0.9231 - val_mse: 0.9231\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9898 - mse: 0.9898 - val_loss: 0.8920 - val_mse: 0.8920\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9667 - mse: 0.9667 - val_loss: 0.8629 - val_mse: 0.8629\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9516 - mse: 0.9516 - val_loss: 0.8363 - val_mse: 0.8363\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9364 - mse: 0.9364 - val_loss: 0.8109 - val_mse: 0.8109\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9118 - mse: 0.9118 - val_loss: 0.7849 - val_mse: 0.7849\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9002 - mse: 0.9002 - val_loss: 0.7605 - val_mse: 0.7605\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8865 - mse: 0.8865 - val_loss: 0.7366 - val_mse: 0.7366\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.8718 - mse: 0.8718 - val_loss: 0.7135 - val_mse: 0.7135\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8601 - mse: 0.8601 - val_loss: 0.6914 - val_mse: 0.6914\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8481 - mse: 0.8481 - val_loss: 0.6703 - val_mse: 0.6703\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8335 - mse: 0.8335 - val_loss: 0.6502 - val_mse: 0.6502\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8238 - mse: 0.8238 - val_loss: 0.6313 - val_mse: 0.6313\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8109 - mse: 0.8109 - val_loss: 0.6134 - val_mse: 0.6134\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8013 - mse: 0.8013 - val_loss: 0.5964 - val_mse: 0.5964\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7887 - mse: 0.7887 - val_loss: 0.5809 - val_mse: 0.5809\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7875 - mse: 0.7875 - val_loss: 0.5664 - val_mse: 0.5664\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7724 - mse: 0.7724 - val_loss: 0.5529 - val_mse: 0.5529\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7590 - mse: 0.7590 - val_loss: 0.5405 - val_mse: 0.5405\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7476 - mse: 0.7476 - val_loss: 0.5288 - val_mse: 0.5288\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7346 - mse: 0.7346 - val_loss: 0.5177 - val_mse: 0.5177\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7228 - mse: 0.7228 - val_loss: 0.5073 - val_mse: 0.5073\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7240 - mse: 0.7240 - val_loss: 0.4972 - val_mse: 0.4972\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7000 - mse: 0.7000 - val_loss: 0.4877 - val_mse: 0.4877\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7174 - mse: 0.7174 - val_loss: 0.4789 - val_mse: 0.4789\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6864 - mse: 0.6864 - val_loss: 0.4703 - val_mse: 0.4703\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6915 - mse: 0.6915 - val_loss: 0.4617 - val_mse: 0.4617\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6797 - mse: 0.6797 - val_loss: 0.4534 - val_mse: 0.4534\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6676 - mse: 0.6676 - val_loss: 0.4452 - val_mse: 0.4452\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6600 - mse: 0.6600 - val_loss: 0.4374 - val_mse: 0.4374\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6535 - mse: 0.6535 - val_loss: 0.4298 - val_mse: 0.4298\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6345 - mse: 0.6345 - val_loss: 0.4224 - val_mse: 0.4224\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6370 - mse: 0.6370 - val_loss: 0.4151 - val_mse: 0.4151\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6305 - mse: 0.6305 - val_loss: 0.4079 - val_mse: 0.4079\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6212 - mse: 0.6212 - val_loss: 0.4008 - val_mse: 0.4008\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6068 - mse: 0.6068 - val_loss: 0.3938 - val_mse: 0.3938\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6079 - mse: 0.6079 - val_loss: 0.3869 - val_mse: 0.3869\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5856 - mse: 0.5856 - val_loss: 0.3801 - val_mse: 0.3801\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5706 - mse: 0.5706 - val_loss: 0.3733 - val_mse: 0.3733\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5703 - mse: 0.5703 - val_loss: 0.3666 - val_mse: 0.3666\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5576 - mse: 0.5576 - val_loss: 0.3600 - val_mse: 0.3600\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5479 - mse: 0.5479 - val_loss: 0.3532 - val_mse: 0.3532\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5462 - mse: 0.5462 - val_loss: 0.3465 - val_mse: 0.3465\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5309 - mse: 0.5309 - val_loss: 0.3398 - val_mse: 0.3398\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5217 - mse: 0.5217 - val_loss: 0.3331 - val_mse: 0.3331\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5067 - mse: 0.5067 - val_loss: 0.3263 - val_mse: 0.3263\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5042 - mse: 0.5042 - val_loss: 0.3193 - val_mse: 0.3193\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4963 - mse: 0.4963 - val_loss: 0.3125 - val_mse: 0.3125\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4922 - mse: 0.4922 - val_loss: 0.3061 - val_mse: 0.3061\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4819 - mse: 0.4819 - val_loss: 0.2997 - val_mse: 0.2997\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4760 - mse: 0.4760 - val_loss: 0.2934 - val_mse: 0.2934\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4619 - mse: 0.4619 - val_loss: 0.2870 - val_mse: 0.2870\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4661 - mse: 0.4661 - val_loss: 0.2806 - val_mse: 0.2806\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4460 - mse: 0.4460 - val_loss: 0.2743 - val_mse: 0.2743\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4352 - mse: 0.4352 - val_loss: 0.2680 - val_mse: 0.2680\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4387 - mse: 0.4387 - val_loss: 0.2618 - val_mse: 0.2618\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4353 - mse: 0.4353 - val_loss: 0.2560 - val_mse: 0.2560\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4129 - mse: 0.4129 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4156 - mse: 0.4156 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4022 - mse: 0.4022 - val_loss: 0.2391 - val_mse: 0.2391\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3906 - mse: 0.3906 - val_loss: 0.2335 - val_mse: 0.2335\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.2279 - val_mse: 0.2279\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3766 - mse: 0.3766 - val_loss: 0.2220 - val_mse: 0.2220\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3678 - mse: 0.3678 - val_loss: 0.2163 - val_mse: 0.2163\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3634 - mse: 0.3634 - val_loss: 0.2109 - val_mse: 0.2109\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3507 - mse: 0.3507 - val_loss: 0.2058 - val_mse: 0.2058\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3476 - mse: 0.3476 - val_loss: 0.2009 - val_mse: 0.2009\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3494 - mse: 0.3494 - val_loss: 0.1960 - val_mse: 0.1960\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3283 - mse: 0.3283 - val_loss: 0.1916 - val_mse: 0.1916\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3198 - mse: 0.3198 - val_loss: 0.1874 - val_mse: 0.1874\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3186 - mse: 0.3186 - val_loss: 0.1835 - val_mse: 0.1835\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3140 - mse: 0.3140 - val_loss: 0.1799 - val_mse: 0.1799\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3039 - mse: 0.3039 - val_loss: 0.1761 - val_mse: 0.1761\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2971 - mse: 0.2971 - val_loss: 0.1723 - val_mse: 0.1723\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2907 - mse: 0.2907 - val_loss: 0.1683 - val_mse: 0.1683\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2825 - mse: 0.2825 - val_loss: 0.1646 - val_mse: 0.1646\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2690 - mse: 0.2690 - val_loss: 0.1606 - val_mse: 0.1606\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2629 - mse: 0.2629 - val_loss: 0.1567 - val_mse: 0.1567\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2629 - mse: 0.2629 - val_loss: 0.1531 - val_mse: 0.1531\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2518 - mse: 0.2518 - val_loss: 0.1491 - val_mse: 0.1491\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2443 - mse: 0.2443 - val_loss: 0.1453 - val_mse: 0.1453\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.1416 - val_mse: 0.1416\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2295 - mse: 0.2295 - val_loss: 0.1375 - val_mse: 0.1375\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 0.1341 - val_mse: 0.1341\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2132 - mse: 0.2132 - val_loss: 0.1311 - val_mse: 0.1311\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2107 - mse: 0.2107 - val_loss: 0.1281 - val_mse: 0.1281\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2210 - mse: 0.2210 - val_loss: 0.1251 - val_mse: 0.1251\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1909 - mse: 0.1909 - val_loss: 0.1222 - val_mse: 0.1222\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1868 - mse: 0.1868 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1908 - mse: 0.1908 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1936 - mse: 0.1936 - val_loss: 0.1150 - val_mse: 0.1150\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1861 - mse: 0.1861 - val_loss: 0.1126 - val_mse: 0.1126\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1800 - mse: 0.1800 - val_loss: 0.1106 - val_mse: 0.1106\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1741 - mse: 0.1741 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1827 - mse: 0.1827 - val_loss: 0.1076 - val_mse: 0.1076\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1724 - mse: 0.1724 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1504 - mse: 0.1504 - val_loss: 0.1036 - val_mse: 0.1036\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.1027 - val_mse: 0.1027\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1584 - mse: 0.1584 - val_loss: 0.1020 - val_mse: 0.1020\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1430 - mse: 0.1430 - val_loss: 0.1013 - val_mse: 0.1013\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1488 - mse: 0.1488 - val_loss: 0.0996 - val_mse: 0.0996\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1538 - mse: 0.1538 - val_loss: 0.0977 - val_mse: 0.0977\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1391 - mse: 0.1391 - val_loss: 0.0958 - val_mse: 0.0958\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1461 - mse: 0.1461 - val_loss: 0.0941 - val_mse: 0.0941\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1448 - mse: 0.1448 - val_loss: 0.0925 - val_mse: 0.0925\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1453 - mse: 0.1453 - val_loss: 0.0912 - val_mse: 0.0912\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1461 - mse: 0.1461 - val_loss: 0.0895 - val_mse: 0.0895\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0883 - val_mse: 0.0883\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 0.0871 - val_mse: 0.0871\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1416 - mse: 0.1416 - val_loss: 0.0864 - val_mse: 0.0864\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 0.0863 - val_mse: 0.0863\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1323 - mse: 0.1323 - val_loss: 0.0858 - val_mse: 0.0858\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1268 - mse: 0.1268 - val_loss: 0.0857 - val_mse: 0.0857\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1306 - mse: 0.1306 - val_loss: 0.0857 - val_mse: 0.0857\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1149 - mse: 0.1149 - val_loss: 0.0858 - val_mse: 0.0858\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1200 - mse: 0.1200 - val_loss: 0.0863 - val_mse: 0.0863\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 0.0862 - val_mse: 0.0862\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.0863 - val_mse: 0.0863\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.0847 - val_mse: 0.0847\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1138 - mse: 0.1138 - val_loss: 0.0833 - val_mse: 0.0833\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1243 - mse: 0.1243 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0813 - val_mse: 0.0813\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 0.0807 - val_mse: 0.0807\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 0.0808 - val_mse: 0.0808\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 0.0813 - val_mse: 0.0813\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.0822 - val_mse: 0.0822\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1216 - mse: 0.1216 - val_loss: 0.0845 - val_mse: 0.0845\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 0.0866 - val_mse: 0.0866\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 0.0875 - val_mse: 0.0875\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.0866 - val_mse: 0.0866\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1248 - mse: 0.1248 - val_loss: 0.0849 - val_mse: 0.0849\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1172 - mse: 0.1172 - val_loss: 0.0844 - val_mse: 0.0844\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 0.0837 - val_mse: 0.0837\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 0.0832 - val_mse: 0.0832\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 0.0830 - val_mse: 0.0830\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0834 - val_mse: 0.0834\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1181 - mse: 0.1181 - val_loss: 0.0842 - val_mse: 0.0842\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.0846 - val_mse: 0.0846\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0848 - val_mse: 0.0848\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1173 - mse: 0.1173 - val_loss: 0.0838 - val_mse: 0.0838\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 0.0828 - val_mse: 0.0828\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0821 - val_mse: 0.0821\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 0.0821 - val_mse: 0.0821\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0822 - val_mse: 0.0822\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.0825 - val_mse: 0.0825\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 0.0832 - val_mse: 0.0832\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 0.0829 - val_mse: 0.0829\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1136 - mse: 0.1136 - val_loss: 0.0825 - val_mse: 0.0825\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0975 - mse: 0.0975 - val_loss: 0.0824 - val_mse: 0.0824\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 0.0826 - val_mse: 0.0826\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1051 - mse: 0.1051 - val_loss: 0.0832 - val_mse: 0.0832\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0956 - mse: 0.0956 - val_loss: 0.0835 - val_mse: 0.0835\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.0841 - val_mse: 0.0841\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.0852 - val_mse: 0.0852\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1060 - mse: 0.1060 - val_loss: 0.0850 - val_mse: 0.0850\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1051 - mse: 0.1051 - val_loss: 0.0844 - val_mse: 0.0844\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 0.0832 - val_mse: 0.0832\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 0.0824 - val_mse: 0.0824\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1068 - mse: 0.1068 - val_loss: 0.0821 - val_mse: 0.0821\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1236 - mse: 0.1236 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 0.0824 - val_mse: 0.0824\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.0835 - val_mse: 0.0835\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.0850 - val_mse: 0.0850\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 0.0855 - val_mse: 0.0855\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 0.0854 - val_mse: 0.0854\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 0.0842 - val_mse: 0.0842\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1200 - mse: 0.1200 - val_loss: 0.0830 - val_mse: 0.0830\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1060 - mse: 0.1060 - val_loss: 0.0815 - val_mse: 0.0815\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0812 - val_mse: 0.0812\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 0.0814 - val_mse: 0.0814\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 0.0817 - val_mse: 0.0817\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0814 - val_mse: 0.0814\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 0.0813 - val_mse: 0.0813\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 0.0816 - val_mse: 0.0816\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0817 - val_mse: 0.0817\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1146 - mse: 0.1146 - val_loss: 0.0815 - val_mse: 0.0815\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0816 - val_mse: 0.0816\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 0.0814 - val_mse: 0.0814\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 0.0820 - val_mse: 0.0820\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0982 - mse: 0.0982 - val_loss: 0.0828 - val_mse: 0.0828\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.0838 - val_mse: 0.0838\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 0.0842 - val_mse: 0.0842\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 0.0839 - val_mse: 0.0839\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0819 - val_mse: 0.0819\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 0.0802 - val_mse: 0.0802\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0790 - val_mse: 0.0790\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.0795 - val_mse: 0.0795\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1022 - mse: 0.1022 - val_loss: 0.0801 - val_mse: 0.0801\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 0.0815 - val_mse: 0.0815\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0988 - mse: 0.0988 - val_loss: 0.0839 - val_mse: 0.0839\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 0.0857 - val_mse: 0.0857\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 0.0862 - val_mse: 0.0862\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.0853 - val_mse: 0.0853\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 0.0827 - val_mse: 0.0827\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1015 - mse: 0.1015 - val_loss: 0.0803 - val_mse: 0.0803\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.0793 - val_mse: 0.0793\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.0791 - val_mse: 0.0791\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1244 - mse: 0.1244 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 0.0793 - val_mse: 0.0793\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.0798 - val_mse: 0.0798\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 0.0808 - val_mse: 0.0808\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 0.0830 - val_mse: 0.0830\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 0.0855 - val_mse: 0.0855\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 0.0877 - val_mse: 0.0877\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 0.0875 - val_mse: 0.0875\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1146 - mse: 0.1146 - val_loss: 0.0862 - val_mse: 0.0862\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0839 - val_mse: 0.0839\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1068 - mse: 0.1068 - val_loss: 0.0818 - val_mse: 0.0818\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1170 - mse: 0.1170 - val_loss: 0.0802 - val_mse: 0.0802\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 0.0789 - val_mse: 0.0789\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0777 - val_mse: 0.0777\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0769 - val_mse: 0.0769\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.0768 - val_mse: 0.0768\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1032 - mse: 0.1032 - val_loss: 0.0774 - val_mse: 0.0774\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1192 - mse: 0.1192 - val_loss: 0.0788 - val_mse: 0.0788\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.0806 - val_mse: 0.0806\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.0824 - val_mse: 0.0824\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 0.0828 - val_mse: 0.0828\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 0.0827 - val_mse: 0.0827\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.0814 - val_mse: 0.0814\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 0.0800 - val_mse: 0.0800\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0784 - val_mse: 0.0784\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.0777 - val_mse: 0.0777\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.0770 - val_mse: 0.0770\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 0.0768 - val_mse: 0.0768\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0769 - val_mse: 0.0769\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 0.0771 - val_mse: 0.0771\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 0.0774 - val_mse: 0.0774\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.0778 - val_mse: 0.0778\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.0788 - val_mse: 0.0788\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0794 - val_mse: 0.0794\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 0.0795 - val_mse: 0.0795\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 0.0790 - val_mse: 0.0790\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 0.0785 - val_mse: 0.0785\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.0780 - val_mse: 0.0780\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0776 - val_mse: 0.0776\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 0.0776 - val_mse: 0.0776\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.0771 - val_mse: 0.0771\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 0.0760 - val_mse: 0.0760\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1051 - mse: 0.1051 - val_loss: 0.0754 - val_mse: 0.0754\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0751 - val_mse: 0.0751\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.0754 - val_mse: 0.0754\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.0770 - val_mse: 0.0770\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.0777 - val_mse: 0.0777\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0783 - val_mse: 0.0783\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0791 - val_mse: 0.0791\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1048 - mse: 0.1048 - val_loss: 0.0790 - val_mse: 0.0790\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0781 - val_mse: 0.0781\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0770 - val_mse: 0.0770\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0765 - val_mse: 0.0765\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0988 - mse: 0.0988 - val_loss: 0.0771 - val_mse: 0.0771\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0773 - val_mse: 0.0773\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.0772 - val_mse: 0.0772\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0924 - mse: 0.0924 - val_loss: 0.0772 - val_mse: 0.0772\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 0.0776 - val_mse: 0.0776\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.0783 - val_mse: 0.0783\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0784 - val_mse: 0.0784\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0782 - val_mse: 0.0782\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1080 - mse: 0.1080 - val_loss: 0.0774 - val_mse: 0.0774\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.0770 - val_mse: 0.0770\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.0765 - val_mse: 0.0765\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.0769 - val_mse: 0.0769\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 0.0772 - val_mse: 0.0772\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.0772 - val_mse: 0.0772\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0995 - mse: 0.0995 - val_loss: 0.0773 - val_mse: 0.0773\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.0775 - val_mse: 0.0775\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0770 - val_mse: 0.0770\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 0.0766 - val_mse: 0.0766\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0760 - val_mse: 0.0760\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0753 - val_mse: 0.0753\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0752 - val_mse: 0.0752\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0754 - val_mse: 0.0754\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0758 - val_mse: 0.0758\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0766 - mse: 0.0766 - val_loss: 0.0758 - val_mse: 0.0758\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1084 - mse: 0.1084 - val_loss: 0.0754 - val_mse: 0.0754\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0752 - val_mse: 0.0752\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0956 - mse: 0.0956 - val_loss: 0.0751 - val_mse: 0.0751\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0753 - val_mse: 0.0753\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0982 - mse: 0.0982 - val_loss: 0.0755 - val_mse: 0.0755\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 0.0753 - val_mse: 0.0753\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 0.0750 - val_mse: 0.0750\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0751 - val_mse: 0.0751\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0755 - val_mse: 0.0755\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0759 - val_mse: 0.0759\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.0763 - val_mse: 0.0763\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.0758 - val_mse: 0.0758\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0754 - val_mse: 0.0754\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0744 - val_mse: 0.0744\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0740 - val_mse: 0.0740\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.0739 - val_mse: 0.0739\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1038 - mse: 0.1038 - val_loss: 0.0740 - val_mse: 0.0740\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.0745 - val_mse: 0.0745\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0750 - val_mse: 0.0750\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0756 - val_mse: 0.0756\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0757 - val_mse: 0.0757\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0764 - val_mse: 0.0764\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.0759 - val_mse: 0.0759\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0750 - val_mse: 0.0750\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 0.0745 - val_mse: 0.0745\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.0743 - val_mse: 0.0743\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0744 - val_mse: 0.0744\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0875 - mse: 0.0875 - val_loss: 0.0743 - val_mse: 0.0743\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 0.0743 - val_mse: 0.0743\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0747 - val_mse: 0.0747\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0752 - val_mse: 0.0752\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0758 - val_mse: 0.0758\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 0.0762 - val_mse: 0.0762\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 0.0757 - val_mse: 0.0757\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.0750 - val_mse: 0.0750\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.0732 - val_mse: 0.0732\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 0.0723 - val_mse: 0.0723\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.0719 - val_mse: 0.0719\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 0.0718 - val_mse: 0.0718\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0719 - val_mse: 0.0719\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0726 - val_mse: 0.0726\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.0740 - val_mse: 0.0740\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0747 - val_mse: 0.0747\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0741 - val_mse: 0.0741\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0737 - val_mse: 0.0737\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0729 - val_mse: 0.0729\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0723 - val_mse: 0.0723\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0720 - val_mse: 0.0720\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0832 - mse: 0.0832 - val_loss: 0.0716 - val_mse: 0.0716\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.0719 - val_mse: 0.0719\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0726 - val_mse: 0.0726\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0734 - val_mse: 0.0734\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.0741 - val_mse: 0.0741\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1038 - mse: 0.1038 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 0.0737 - val_mse: 0.0737\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.0731 - val_mse: 0.0731\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0727 - val_mse: 0.0727\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0715 - val_mse: 0.0715\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.0709 - val_mse: 0.0709\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0707 - val_mse: 0.0707\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0707 - val_mse: 0.0707\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0713 - val_mse: 0.0713\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0803 - mse: 0.0803 - val_loss: 0.0721 - val_mse: 0.0721\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0732 - val_mse: 0.0732\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0741 - val_mse: 0.0741\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 0.0744 - val_mse: 0.0744\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0803 - mse: 0.0803 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.0736 - val_mse: 0.0736\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0729 - val_mse: 0.0729\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0720 - val_mse: 0.0720\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.0710 - val_mse: 0.0710\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0707 - val_mse: 0.0707\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0706 - val_mse: 0.0706\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0707 - val_mse: 0.0707\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.0710 - val_mse: 0.0710\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0716 - val_mse: 0.0716\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0721 - val_mse: 0.0721\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0723 - val_mse: 0.0723\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 0.0722 - val_mse: 0.0722\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0720 - val_mse: 0.0720\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0713 - val_mse: 0.0713\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 0.0705 - val_mse: 0.0705\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.0696 - val_mse: 0.0696\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 0.0690 - val_mse: 0.0690\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.0687 - val_mse: 0.0687\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0688 - val_mse: 0.0688\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0690 - val_mse: 0.0690\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0695 - val_mse: 0.0695\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 0.0700 - val_mse: 0.0700\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.0705 - val_mse: 0.0705\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0784 - mse: 0.0784 - val_loss: 0.0708 - val_mse: 0.0708\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0711 - val_mse: 0.0711\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0712 - val_mse: 0.0712\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0707 - val_mse: 0.0707\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.0700 - val_mse: 0.0700\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0695 - val_mse: 0.0695\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0688 - val_mse: 0.0688\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0681 - val_mse: 0.0681\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0678 - val_mse: 0.0678\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0791 - mse: 0.0791 - val_loss: 0.0678 - val_mse: 0.0678\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0684 - val_mse: 0.0684\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0695 - val_mse: 0.0695\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 0.0704 - val_mse: 0.0704\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.0704 - val_mse: 0.0704\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 0.0697 - val_mse: 0.0697\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0685 - val_mse: 0.0685\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0675 - val_mse: 0.0675\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0666 - val_mse: 0.0666\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0656 - val_mse: 0.0656\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 0.0653 - val_mse: 0.0653\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.0663 - val_mse: 0.0663\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0681 - val_mse: 0.0681\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0699 - val_mse: 0.0699\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0712 - val_mse: 0.0712\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0706 - val_mse: 0.0706\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0690 - val_mse: 0.0690\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0670 - val_mse: 0.0670\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0653 - val_mse: 0.0653\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0914 - mse: 0.0914 - val_loss: 0.0637 - val_mse: 0.0637\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 0.0637 - val_mse: 0.0637\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0639 - val_mse: 0.0639\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0809 - mse: 0.0809 - val_loss: 0.0645 - val_mse: 0.0645\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0657 - val_mse: 0.0657\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0670 - val_mse: 0.0670\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0678 - val_mse: 0.0678\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0680 - val_mse: 0.0680\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0673 - val_mse: 0.0673\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.0665 - val_mse: 0.0665\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0655 - val_mse: 0.0655\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0761 - mse: 0.0761 - val_loss: 0.0648 - val_mse: 0.0648\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.0645 - val_mse: 0.0645\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0646 - val_mse: 0.0646\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0649 - val_mse: 0.0649\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0732 - mse: 0.0732 - val_loss: 0.0652 - val_mse: 0.0652\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0656 - val_mse: 0.0656\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0658 - val_mse: 0.0658\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0660 - val_mse: 0.0660\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0658 - val_mse: 0.0658\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0655 - val_mse: 0.0655\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0772 - mse: 0.0772 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0647 - val_mse: 0.0647\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0645 - val_mse: 0.0645\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0649 - val_mse: 0.0649\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0652 - val_mse: 0.0652\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0772 - mse: 0.0772 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.0652 - val_mse: 0.0652\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0654 - val_mse: 0.0654\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 0.0654 - val_mse: 0.0654\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0655 - val_mse: 0.0655\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0652 - val_mse: 0.0652\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0648 - val_mse: 0.0648\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0646 - val_mse: 0.0646\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0815 - mse: 0.0815 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0645 - val_mse: 0.0645\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0791 - mse: 0.0791 - val_loss: 0.0645 - val_mse: 0.0645\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 0.0648 - val_mse: 0.0648\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 0.0652 - val_mse: 0.0652\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0790 - mse: 0.0790 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0647 - val_mse: 0.0647\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0640 - val_mse: 0.0640\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0725 - mse: 0.0725 - val_loss: 0.0641 - val_mse: 0.0641\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0647 - val_mse: 0.0647\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0832 - mse: 0.0832 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0646 - val_mse: 0.0646\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0726 - mse: 0.0726 - val_loss: 0.0641 - val_mse: 0.0641\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0637 - val_mse: 0.0637\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 0.0632 - val_mse: 0.0632\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0629 - val_mse: 0.0629\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0625 - val_mse: 0.0625\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0625 - val_mse: 0.0625\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0627 - val_mse: 0.0627\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0773 - mse: 0.0773 - val_loss: 0.0630 - val_mse: 0.0630\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0634 - val_mse: 0.0634\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0784 - mse: 0.0784 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0758 - mse: 0.0758 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0627 - val_mse: 0.0627\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0625 - val_mse: 0.0625\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0623 - val_mse: 0.0623\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0621 - val_mse: 0.0621\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0622 - val_mse: 0.0622\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0625 - val_mse: 0.0625\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0632 - val_mse: 0.0632\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0632 - val_mse: 0.0632\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0629 - val_mse: 0.0629\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0624 - val_mse: 0.0624\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0622 - val_mse: 0.0622\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0621 - val_mse: 0.0621\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0620 - val_mse: 0.0620\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0618 - val_mse: 0.0618\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0617 - val_mse: 0.0617\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0615 - val_mse: 0.0615\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0618 - val_mse: 0.0618\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0619 - val_mse: 0.0619\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0619 - val_mse: 0.0619\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.0620 - val_mse: 0.0620\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0623 - val_mse: 0.0623\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0624 - val_mse: 0.0624\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0797 - mse: 0.0797 - val_loss: 0.0625 - val_mse: 0.0625\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0627 - val_mse: 0.0627\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0629 - val_mse: 0.0629\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0628 - val_mse: 0.0628\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0622 - val_mse: 0.0622\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0609 - val_mse: 0.0609\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0609 - val_mse: 0.0609\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0610 - val_mse: 0.0610\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0612 - val_mse: 0.0612\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0615 - val_mse: 0.0615\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0612 - val_mse: 0.0612\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0610 - val_mse: 0.0610\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0610 - val_mse: 0.0610\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0617 - val_mse: 0.0617\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0619 - val_mse: 0.0619\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0617 - val_mse: 0.0617\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0615 - val_mse: 0.0615\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 0.0606 - val_mse: 0.0606\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0717 - mse: 0.0717 - val_loss: 0.0599 - val_mse: 0.0599\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0599 - val_mse: 0.0599\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0606 - val_mse: 0.0606\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0758 - mse: 0.0758 - val_loss: 0.0617 - val_mse: 0.0617\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0620 - val_mse: 0.0620\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0741 - mse: 0.0741 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0610 - val_mse: 0.0610\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0655 - mse: 0.0655 - val_loss: 0.0605 - val_mse: 0.0605\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0599 - val_mse: 0.0599\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0605 - val_mse: 0.0605\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0610 - val_mse: 0.0610\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0615 - val_mse: 0.0615\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0617 - val_mse: 0.0617\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0613 - val_mse: 0.0613\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0606 - val_mse: 0.0606\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0748 - mse: 0.0748 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0586 - val_mse: 0.0586\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0596 - val_mse: 0.0596\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0603 - val_mse: 0.0603\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0607 - val_mse: 0.0607\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0608 - val_mse: 0.0608\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0607 - val_mse: 0.0607\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0600 - val_mse: 0.0600\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0841 - mse: 0.0841 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0585 - val_mse: 0.0585\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0596 - val_mse: 0.0596\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0596 - val_mse: 0.0596\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0594 - val_mse: 0.0594\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0592 - val_mse: 0.0592\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0588 - val_mse: 0.0588\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0588 - val_mse: 0.0588\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0603 - val_mse: 0.0603\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0600 - val_mse: 0.0600\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0589 - val_mse: 0.0589\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0589 - val_mse: 0.0589\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0588 - val_mse: 0.0588\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0585 - val_mse: 0.0585\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0580 - val_mse: 0.0580\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0660 - mse: 0.0660 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0588 - val_mse: 0.0588\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0591 - val_mse: 0.0591\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0580 - val_mse: 0.0580\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0586 - val_mse: 0.0586\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0592 - val_mse: 0.0592\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0603 - val_mse: 0.0603\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0595 - val_mse: 0.0595\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0589 - val_mse: 0.0589\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0567 - mse: 0.0567 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0585 - val_mse: 0.0585\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0586 - val_mse: 0.0586\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0622 - mse: 0.0622 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0580 - val_mse: 0.0580\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0616 - mse: 0.0616 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0655 - mse: 0.0655 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0624 - mse: 0.0624 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0622 - mse: 0.0622 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0515 - val_mse: 0.0515\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0516 - val_mse: 0.0516\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0624 - mse: 0.0624 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0516 - val_mse: 0.0516\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0522 - val_mse: 0.0522\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0523 - val_mse: 0.0523\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0531 - val_mse: 0.0531\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0538 - val_mse: 0.0538\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0535 - val_mse: 0.0535\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0580 - val_mse: 0.0580\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0542 - val_mse: 0.0542\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0580 - val_mse: 0.0580\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0583 - val_mse: 0.0583\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0543 - val_mse: 0.0543\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0540 - val_mse: 0.0540\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0574 - val_mse: 0.0574\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0552 - val_mse: 0.0552\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0554 - val_mse: 0.0554\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0571 - val_mse: 0.0571\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0577 - val_mse: 0.0577\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0558 - val_mse: 0.0558\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0568 - val_mse: 0.0568\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0565 - val_mse: 0.0565\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0570 - val_mse: 0.0570\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0563 - val_mse: 0.0563\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0564 - val_mse: 0.0564\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0567 - val_mse: 0.0567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l8g2s4Ogwt7"
      },
      "source": [
        "Plot loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ksInevx1gt33",
        "outputId": "fa4975fb-ab75-47bb-a905-0d7a7cec8f0d"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.2])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plot_loss(history)\n"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhWj-M9sWa1A"
      },
      "source": [
        "Evaluate neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAGobBA6XfTt",
        "outputId": "da6ed1a3-18d2-4cca-a3bd-437f1787c22c"
      },
      "source": [
        "results = model0.evaluate(XX_test_n, yy_test_n)\n",
        "\n",
        "print('loss test data: ', results[0])\n",
        "print('mse test data: ', results[1])\n",
        "\n",
        "results = model0.evaluate(XX_train_n, yy_train_n)\n",
        "\n",
        "print('loss train data: ', results[0])\n",
        "print('mse train data: ', results[1])"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0567 - mse: 0.0567\n",
            "loss test data:  0.056734029203653336\n",
            "mse test data:  0.056734029203653336\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415\n",
            "loss train data:  0.041536346077919006\n",
            "mse train data:  0.041536346077919006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qv-t09rWgT8"
      },
      "source": [
        "Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "JwHkHPnzvD_z",
        "outputId": "0961c728-7660-4cfc-d3a4-2b4e091e1e61"
      },
      "source": [
        "fig = plt.figure(figsize=(7,7))\n",
        "\n",
        "plt.plot(XX_train_n,yy_train_n, 'o', color='blue', label='Training points')\n",
        "plt.plot(XX_test_n,yy_test_n, 'o', color='green', label='Testing points')\n",
        "\n",
        "points = np.linspace(min(XX_test_n), max(XX_test_n),num=100)\n",
        "plt.plot(points, (funct(points*std+mean)-meany)/stdy,  color='red', label='Function')\n",
        "\n",
        "plt.plot(points, model0.predict(points),  color='orange', label='Neural net')\n",
        "\n",
        "#plt.plot(XX_train_n, model0.predict(XX_train_n), 'o',  color='red', label='NN')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnwcHVfaHJif"
      },
      "source": [
        "**The Boston Housing Price dataset**\n",
        "\n",
        "We will be attempting to predict the median price of homes in a given Boston suburb in the mid-1970s, given a few data points about the suburb at the time, such as the crime rate, the local property tax rate, etc.\n",
        "\n",
        "The dataset has very few data points, only 506 in total, split between 404 training samples and 102 test samples, and each \"feature\" in the input data (e.g. the crime rate is a feature) has a different scale. For instance some values are proportions, which take a values between 0 and 1, others take values between 1 and 12, others between 0 and 100..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__lqdBmD9cgL"
      },
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDCcGuFW9RP6"
      },
      "source": [
        "\n",
        "**Preparing the data**\n",
        "\n",
        "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a unit standard deviation. This is easily done in Numpy:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRPumcs09RP7"
      },
      "source": [
        "mean = X_train.mean(axis=0)\n",
        "X_train_n = X_train-mean\n",
        "std = X_train_n.std(axis=0)\n",
        "X_train_n /= std\n",
        "\n",
        "X_test_n = X_test - mean\n",
        "X_test_n /= std\n",
        "\n",
        "meany = y_train.mean(axis=0)\n",
        "y_train_n = y_train - meany\n",
        "stdy = y_train_n.std(axis=0)\n",
        "y_train_n /= stdy\n",
        "\n",
        "y_test_n = y_test - meany\n",
        "y_test_n /= stdy\n",
        "\n",
        "\n",
        "\n",
        "#XX_train_n = XX_train_n.reshape((len(XX_train_n),1))\n",
        "#XX_test_n  = XX_test_n.reshape((len(XX_test_n),1))\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuj5f4Mg6e5y",
        "outputId": "45e183af-79e6-489a-9312-3b63271dbd62"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Keras model with two hidden layer with 10 neurons each \n",
        "model.add(Dense(8, input_shape = (X_train.shape[1],)))    # Input layer => input_shape should be explicitly designated\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.01))\n",
        "model.add(Dense(8))                         # Hidden layer => only output dimension should be designated\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.01))\n",
        "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
        "\n",
        "\n",
        "#sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
        "history = model.fit(X_train_n, y_train_n, batch_size = 50, epochs = 200, verbose = 1, validation_data=(X_test_n,y_test_n))\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.3220 - mse: 1.3220 - val_loss: 1.3613 - val_mse: 1.3613\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1983 - mse: 1.1983 - val_loss: 1.2390 - val_mse: 1.2390\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1089 - mse: 1.1089 - val_loss: 1.1489 - val_mse: 1.1489\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0395 - mse: 1.0395 - val_loss: 1.0736 - val_mse: 1.0736\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9754 - mse: 0.9754 - val_loss: 0.9972 - val_mse: 0.9972\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9152 - mse: 0.9152 - val_loss: 0.9046 - val_mse: 0.9046\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8545 - mse: 0.8545 - val_loss: 0.8584 - val_mse: 0.8584\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8151 - mse: 0.8151 - val_loss: 0.8095 - val_mse: 0.8095\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7744 - mse: 0.7744 - val_loss: 0.7554 - val_mse: 0.7554\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7314 - mse: 0.7314 - val_loss: 0.6800 - val_mse: 0.6800\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6787 - mse: 0.6787 - val_loss: 0.6214 - val_mse: 0.6214\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6341 - mse: 0.6341 - val_loss: 0.5816 - val_mse: 0.5816\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6009 - mse: 0.6009 - val_loss: 0.5490 - val_mse: 0.5490\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5701 - mse: 0.5701 - val_loss: 0.5118 - val_mse: 0.5118\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5362 - mse: 0.5362 - val_loss: 0.4741 - val_mse: 0.4741\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5012 - mse: 0.5012 - val_loss: 0.4350 - val_mse: 0.4350\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4704 - mse: 0.4704 - val_loss: 0.4011 - val_mse: 0.4011\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4387 - mse: 0.4387 - val_loss: 0.3721 - val_mse: 0.3721\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4129 - mse: 0.4129 - val_loss: 0.3475 - val_mse: 0.3475\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3903 - mse: 0.3903 - val_loss: 0.3255 - val_mse: 0.3255\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3688 - mse: 0.3688 - val_loss: 0.3019 - val_mse: 0.3019\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3464 - mse: 0.3464 - val_loss: 0.2766 - val_mse: 0.2766\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3232 - mse: 0.3232 - val_loss: 0.2663 - val_mse: 0.2663\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3085 - mse: 0.3085 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2942 - mse: 0.2942 - val_loss: 0.2415 - val_mse: 0.2415\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2804 - mse: 0.2804 - val_loss: 0.2330 - val_mse: 0.2330\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2639 - mse: 0.2639 - val_loss: 0.2281 - val_mse: 0.2281\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2552 - mse: 0.2552 - val_loss: 0.2311 - val_mse: 0.2311\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2453 - mse: 0.2453 - val_loss: 0.2201 - val_mse: 0.2201\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2190 - val_mse: 0.2190\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 0.2174 - val_mse: 0.2174\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.2131 - val_mse: 0.2131\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2104 - val_mse: 0.2104\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2091 - val_mse: 0.2091\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2053 - mse: 0.2053 - val_loss: 0.2096 - val_mse: 0.2096\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1995 - mse: 0.1995 - val_loss: 0.2118 - val_mse: 0.2118\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1958 - mse: 0.1958 - val_loss: 0.2154 - val_mse: 0.2154\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1926 - mse: 0.1926 - val_loss: 0.2060 - val_mse: 0.2060\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1898 - mse: 0.1898 - val_loss: 0.2053 - val_mse: 0.2053\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1860 - mse: 0.1860 - val_loss: 0.2076 - val_mse: 0.2076\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1826 - mse: 0.1826 - val_loss: 0.2044 - val_mse: 0.2044\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1784 - mse: 0.1784 - val_loss: 0.2060 - val_mse: 0.2060\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1762 - mse: 0.1762 - val_loss: 0.2050 - val_mse: 0.2050\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1732 - mse: 0.1732 - val_loss: 0.2036 - val_mse: 0.2036\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.2042 - val_mse: 0.2042\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1681 - mse: 0.1681 - val_loss: 0.2012 - val_mse: 0.2012\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1653 - mse: 0.1653 - val_loss: 0.2047 - val_mse: 0.2047\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1633 - mse: 0.1633 - val_loss: 0.2032 - val_mse: 0.2032\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1611 - mse: 0.1611 - val_loss: 0.2051 - val_mse: 0.2051\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1587 - mse: 0.1587 - val_loss: 0.2035 - val_mse: 0.2035\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1573 - mse: 0.1573 - val_loss: 0.2031 - val_mse: 0.2031\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1562 - mse: 0.1562 - val_loss: 0.2054 - val_mse: 0.2054\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1536 - mse: 0.1536 - val_loss: 0.2077 - val_mse: 0.2077\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1522 - mse: 0.1522 - val_loss: 0.2184 - val_mse: 0.2184\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1507 - mse: 0.1507 - val_loss: 0.2227 - val_mse: 0.2227\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1484 - mse: 0.1484 - val_loss: 0.2180 - val_mse: 0.2180\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1469 - mse: 0.1469 - val_loss: 0.2211 - val_mse: 0.2211\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1468 - mse: 0.1468 - val_loss: 0.2144 - val_mse: 0.2144\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 0.2145 - val_mse: 0.2145\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1439 - mse: 0.1439 - val_loss: 0.2107 - val_mse: 0.2107\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1439 - mse: 0.1439 - val_loss: 0.2125 - val_mse: 0.2125\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1425 - mse: 0.1425 - val_loss: 0.2071 - val_mse: 0.2071\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.2116 - val_mse: 0.2116\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1401 - mse: 0.1401 - val_loss: 0.2100 - val_mse: 0.2100\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1404 - mse: 0.1404 - val_loss: 0.2138 - val_mse: 0.2138\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.2180 - val_mse: 0.2180\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1369 - mse: 0.1369 - val_loss: 0.2095 - val_mse: 0.2095\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1375 - mse: 0.1375 - val_loss: 0.2176 - val_mse: 0.2176\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1349 - mse: 0.1349 - val_loss: 0.2347 - val_mse: 0.2347\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 0.2236 - val_mse: 0.2236\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1336 - mse: 0.1336 - val_loss: 0.2166 - val_mse: 0.2166\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 0.2286 - val_mse: 0.2286\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1323 - mse: 0.1323 - val_loss: 0.2248 - val_mse: 0.2248\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 0.2239 - val_mse: 0.2239\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1304 - mse: 0.1304 - val_loss: 0.2358 - val_mse: 0.2358\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1316 - mse: 0.1316 - val_loss: 0.2255 - val_mse: 0.2255\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 0.2273 - val_mse: 0.2273\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 0.2279 - val_mse: 0.2279\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1279 - mse: 0.1279 - val_loss: 0.2216 - val_mse: 0.2216\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 0.2182 - val_mse: 0.2182\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1277 - mse: 0.1277 - val_loss: 0.2149 - val_mse: 0.2149\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 0.2200 - val_mse: 0.2200\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 0.2130 - val_mse: 0.2130\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1250 - mse: 0.1250 - val_loss: 0.2081 - val_mse: 0.2081\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1247 - mse: 0.1247 - val_loss: 0.2125 - val_mse: 0.2125\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1239 - mse: 0.1239 - val_loss: 0.2224 - val_mse: 0.2224\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1237 - mse: 0.1237 - val_loss: 0.2180 - val_mse: 0.2180\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1233 - mse: 0.1233 - val_loss: 0.2290 - val_mse: 0.2290\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 0.2094 - val_mse: 0.2094\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1227 - mse: 0.1227 - val_loss: 0.2199 - val_mse: 0.2199\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 0.2090 - val_mse: 0.2090\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 0.2219 - val_mse: 0.2219\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 0.2155 - val_mse: 0.2155\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.2164 - val_mse: 0.2164\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.2185 - val_mse: 0.2185\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 0.2067 - val_mse: 0.2067\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 0.2187 - val_mse: 0.2187\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.2109 - val_mse: 0.2109\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.2201 - val_mse: 0.2201\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.2228 - val_mse: 0.2228\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1162 - mse: 0.1162 - val_loss: 0.2185 - val_mse: 0.2185\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 0.2102 - val_mse: 0.2102\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 0.2195 - val_mse: 0.2195\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1155 - mse: 0.1155 - val_loss: 0.2194 - val_mse: 0.2194\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1145 - mse: 0.1145 - val_loss: 0.2274 - val_mse: 0.2274\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 0.2124 - val_mse: 0.2124\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.2001 - val_mse: 0.2001\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 0.2059 - val_mse: 0.2059\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 0.2113 - val_mse: 0.2113\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 0.2171 - val_mse: 0.2171\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 0.2124 - val_mse: 0.2124\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1125 - mse: 0.1125 - val_loss: 0.2066 - val_mse: 0.2066\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1115 - mse: 0.1115 - val_loss: 0.1977 - val_mse: 0.1977\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1115 - mse: 0.1115 - val_loss: 0.2095 - val_mse: 0.2095\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1102 - mse: 0.1102 - val_loss: 0.2239 - val_mse: 0.2239\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1104 - mse: 0.1104 - val_loss: 0.2147 - val_mse: 0.2147\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 0.2081 - val_mse: 0.2081\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 0.2155 - val_mse: 0.2155\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 0.2208 - val_mse: 0.2208\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 0.2176 - val_mse: 0.2175\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 0.2175 - val_mse: 0.2175\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1082 - mse: 0.1082 - val_loss: 0.2111 - val_mse: 0.2111\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 0.2194 - val_mse: 0.2194\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1083 - mse: 0.1083 - val_loss: 0.2031 - val_mse: 0.2031\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 0.1992 - val_mse: 0.1992\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.2042 - val_mse: 0.2042\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 0.2029 - val_mse: 0.2029\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 0.2012 - val_mse: 0.2012\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.1998 - val_mse: 0.1998\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 0.1930 - val_mse: 0.1930\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 0.1941 - val_mse: 0.1941\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1039 - mse: 0.1039 - val_loss: 0.2114 - val_mse: 0.2114\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 0.2051 - val_mse: 0.2051\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 0.2073 - val_mse: 0.2073\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1031 - mse: 0.1031 - val_loss: 0.2139 - val_mse: 0.2139\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1030 - mse: 0.1030 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.1925 - val_mse: 0.1925\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 0.1888 - val_mse: 0.1888\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 0.1934 - val_mse: 0.1934\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 0.1943 - val_mse: 0.1943\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1014 - mse: 0.1014 - val_loss: 0.1924 - val_mse: 0.1924\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1011 - mse: 0.1011 - val_loss: 0.1876 - val_mse: 0.1876\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.1859 - val_mse: 0.1859\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1010 - mse: 0.1010 - val_loss: 0.1875 - val_mse: 0.1875\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 0.1908 - val_mse: 0.1908\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.1873 - val_mse: 0.1873\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.1974 - val_mse: 0.1974\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 0.1914 - val_mse: 0.1914\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.1902 - val_mse: 0.1902\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.1854 - val_mse: 0.1854\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.1725 - val_mse: 0.1725\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.1770 - val_mse: 0.1770\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0975 - mse: 0.0975 - val_loss: 0.1786 - val_mse: 0.1786\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 0.1943 - val_mse: 0.1943\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.1912 - val_mse: 0.1912\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.1842 - val_mse: 0.1842\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 0.1898 - val_mse: 0.1898\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0956 - mse: 0.0956 - val_loss: 0.1921 - val_mse: 0.1921\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.1970 - val_mse: 0.1970\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.1859 - val_mse: 0.1859\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.2024 - val_mse: 0.2024\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.1913 - val_mse: 0.1913\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.1862 - val_mse: 0.1862\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.1855 - val_mse: 0.1855\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.1794 - val_mse: 0.1794\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.1775 - val_mse: 0.1775\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.1735 - val_mse: 0.1735\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.1807 - val_mse: 0.1807\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 0.1808 - val_mse: 0.1808\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.1798 - val_mse: 0.1798\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 0.1830 - val_mse: 0.1830\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.1707 - val_mse: 0.1707\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.1851 - val_mse: 0.1851\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.1839 - val_mse: 0.1839\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 0.1857 - val_mse: 0.1857\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.1823 - val_mse: 0.1823\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.1850 - val_mse: 0.1850\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.1709 - val_mse: 0.1709\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.1961 - val_mse: 0.1961\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.1805 - val_mse: 0.1805\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.1860 - val_mse: 0.1860\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.1734 - val_mse: 0.1734\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 0.1805 - val_mse: 0.1805\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.1763 - val_mse: 0.1763\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 0.1657 - val_mse: 0.1657\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.1642 - val_mse: 0.1642\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.1745 - val_mse: 0.1745\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.1699 - val_mse: 0.1699\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.1630 - val_mse: 0.1630\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 0.1712 - val_mse: 0.1712\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.1746 - val_mse: 0.1746\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.1688 - val_mse: 0.1688\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.1620 - val_mse: 0.1620\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.1659 - val_mse: 0.1659\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.1671 - val_mse: 0.1671\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.1695 - val_mse: 0.1695\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.1625 - val_mse: 0.1625\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.1741 - val_mse: 0.1741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "86NDw6Qm91dC",
        "outputId": "74cafccb-c506-475a-a537-eb408c284c96"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.5])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plot_loss(history)\n"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dewsTB7XbAh",
        "outputId": "114c53f9-234c-48cd-f0b1-fc3fe8d6ec9f"
      },
      "source": [
        "results = model.evaluate(X_test_n, y_test_n)\n",
        "\n",
        "print('loss test data: ', results[0])\n",
        "print('mse test data: ', results[1])\n",
        "\n",
        "results = model.evaluate(X_train_n, y_train_n)\n",
        "\n",
        "print('loss train data: ', results[0])\n",
        "print('mse train data: ', results[1])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2560 - mse: 0.2560\n",
            "loss test data:  0.25595352053642273\n",
            "mse test data:  0.25595352053642273\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.1079\n",
            "loss train data:  0.10794869065284729\n",
            "mse train data:  0.10794869065284729\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}